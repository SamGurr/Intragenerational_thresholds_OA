TP.Standards.MERGE.1 <- merge(TP.Standards.concentration, TP.Standards.means, by=c('ID')) # merge with the means by ID to add theoretical BCA values
TP.Standards.MERGE.FINAL <- merge(TP.Standards.MERGE.1, TP.Blanks.means, by=c('Date', 'Run')) # merge with the mean blanks to correct BELOW
TP.Standards.MERGE.FINAL$mean.absorbance.CORRECTED <- TP.Standards.MERGE.FINAL$mean.absorbance - TP.Standards.MERGE.FINAL$mean.blank # correct to mean blank absorbance as "mean.absorbance.CORRECTED"
# NOTE: max standard is 2.6290
# SAMPLES ANNNALYZED ON 11/04
TP.Standards.Nov <- TP.Standards.MERGE.FINAL %>% dplyr::filter(Date == '20191104')
TP.Standards.model.Nov <- lm(mean.absorbance.CORRECTED ~ mg.mL_BCA, data=TP.Standards.Nov) #runs a linear regression of mV as a function of temperature
TP.b.Nov <- summary(TP.Standards.model.Nov)$coefficients[1] # 0.04205469
TP.m.Nov <- summary(TP.Standards.model.Nov)$coefficients[2] # 1.334554
TP.R2.Nov<-summary(TP.Standards.model.Nov)$r.squared # 0.9967063
plot(mean.absorbance.CORRECTED ~ mg.mL_BCA, data=TP.Standards.Nov)
summary(lm(mean.absorbance.CORRECTED ~ mg.mL_BCA, data=TP.Standards.Nov)) # Adjusted R-squared:  0.9962
abline(lm(mean.absorbance.CORRECTED ~ mg.mL_BCA, data=TP.Standards.Nov))
legend('topleft', legend = c((bquote(R^2 == .(format(TP.R2.Nov), digits = 5))),
(bquote(slope == .(format(TP.m.Nov), digits = 5))),
(bquote(intercept == .(format(TP.b.Nov), digits = 5)))),  bty='n')
# SAMPLES ANNNALYZED ON 12/16
TP.Standards.Dec <- TP.Standards.MERGE.FINAL %>% dplyr::filter(Date == '20191216')
TP.Standards.model.Dec <- lm(mean.absorbance.CORRECTED ~ mg.mL_BCA, data=TP.Standards.Dec) #runs a linear regression of mV as a function of temperature
TP.b.Dec <- summary(TP.Standards.model.Dec)$coefficients[1] # 0.04445541
TP.m.Dec <- summary(TP.Standards.model.Dec)$coefficients[2] # 1.299334
TP.R2.Dec <-summary(TP.Standards.model.Dec)$r.squared #  0.9953494
plot(mean.absorbance.CORRECTED ~ mg.mL_BCA, data=TP.Standards.Dec)
summary(lm(mean.absorbance.CORRECTED ~ mg.mL_BCA, data=TP.Standards.Dec)) # Adjusted R-squared:  0.9947
abline(lm(mean.absorbance.CORRECTED ~ mg.mL_BCA, data=TP.Standards.Dec))
legend('topleft', legend = c((bquote(R^2 == .(format(TP.R2.Dec), digits = 5))),
(bquote(slope == .(format(TP.m.Dec), digits = 5))),
(bquote(intercept == .(format(TP.b.Dec), digits = 5)))),  bty='n')
# 6. ------------------------------------------------------------------------------------------------------------------------------------------ #
# remove standards from data, Calculate Total Protein
TP.Samples.DF <- TP.MERGE.Reference %>% dplyr::filter(!Type == "Standard") # remove standards
TP.MASTER.DF <- merge(TP.Samples.DF, TP.Blanks.means, by=c('Date')) # align blank values by date and run to correct absorbance values
tail(TP.MASTER.DF) # view newer data
TP.MASTER.DF$Absorbance.CORRECTED <- (TP.MASTER.DF$Absorbance.RAW -  TP.MASTER.DF$mean.blank) # subtract from the blank on the corresponding date (aligned from merge)
TP.MASTER.DF.Nov <-  TP.MASTER.DF %>% dplyr::filter(Date == '20191104')
TP.MASTER.DF.Nov$mg.mL_BCA  <- ((TP.MASTER.DF.Nov$Absorbance.CORRECTED - TP.b.Nov)/TP.m.Nov) # Calculate µg.mL_BCA
plot(Absorbance.CORRECTED ~ mg.mL_BCA, data=TP.MASTER.DF.Nov) # plot the data
TP.MASTER.DF.Dec <-  TP.MASTER.DF %>% dplyr::filter(Date == '20191216')
TP.MASTER.DF.Dec$mg.mL_BCA  <- ((TP.MASTER.DF.Dec$Absorbance.CORRECTED - TP.b.Dec)/TP.m.Dec) # Calculate µg.mL_BCA
plot(Absorbance.CORRECTED ~ mg.mL_BCA, data=TP.MASTER.DF.Dec) # plot the data
TP.MASTER.DF.2 <- rbind(TP.MASTER.DF.Nov,TP.MASTER.DF.Dec) # view total protein dataframe
TP.MASTER.DF.2 <- na.omit(TP.MASTER.DF.2) # removes both duplicate measurements of ID 1161 and ONE measurement of ID 205 (over the spectrum of spec)
# 7. ------------------------------------------------------------------------------------------------------------------------------------------ #
# Summarize by ID to obtain the median (assay completed in duplicates)
MASTER.TP.MEANS <- TP.MASTER.DF.2 %>%
# dplyr::filter(Absorbance.CORRECTED < 2.6290) %>%
dplyr::group_by(Date, ID) %>% # call column to summarize
dplyr::summarise(mean.mg.mL_BCA = mean(mg.mL_BCA),
count.mean.µg.mL_BCA = n())
MASTER.TP.MEANS # view the table of mean values (actually the median of duplicates - prints the single value for readings not duplicated, e.g. 205)
################################################################################################################################## #
################################################################################################################################## #
###############################################################  TOTAL ANTIOXIDANT CAPACITY  #####################################
################################################################### OXISELECT ASSSAY     ######################################### #
################################################################################################################################## #
# NOTE! this assay has both initial and post reaction absorbance readings  ####################################################### #
# FOR LOOP to for a cumulative dataset of all TAC runs ---------------------------------------------------------------------------------- #
# PRE for loop prep
path.TAC.files<-"Data/Phys.assays/TAC_data/csv.files" #the location of all TAC spec files (.csv format)
TAC.file.names.full<-basename(list.files(path = path.TAC.files, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
TAC.file.names.full # look at the names of the csv files you will call in the following for loop
# INSIDE for loop prep
DF.TAC <- data.frame(matrix(nrow = 96, ncol = 5))  # first create a master data table to bind in the for loop
colnames(DF.TAC)<-c('Date', 'Run', 'Well', 'Absorbance.RAW', 'Initial.Post') # column names, matches all data
DF.TAC.TOTAL <- data.frame() # start dataframe
# RUN FOR LOOP
for(i in 1:length(TAC.file.names.full)) { # for every file name in list
TAC.Data <-read.table(file.path(path.TAC.files, TAC.file.names.full[i]),
header=T, sep=",", na.string="NA",
fill = TRUE, as.is=TRUE) # reads in the data files of that name one by one
DF.TAC$Date <- substr(TAC.file.names.full[i], 1,8) # date from file name
DF.TAC$Run <- substr(TAC.file.names.full[i], 14,14) # Run number from file name
DF.TAC$Well <- TAC.Data[,1] # row containing the well ID
DF.TAC$Initial.Post <- substr(TAC.file.names.full[i], 16,16) # first letter of 'initial' or 'post' in file name
DF.TAC$Absorbance.RAW <- TAC.Data[,2] # raw absorbance value
DF.loop <- data.frame(DF.TAC) # assign the table to a different name
DF.TAC.TOTAL <- rbind(DF.TAC.TOTAL,DF.loop) # bind the newly named table to a cumulative dataframe
print(DF.TAC.TOTAL) # print to monitor progress
# script returns to next file in order and creates a new DF.TAC to rename as DF.loop and bind to DF.TAC.TOTAL wihtin the for loop
}
DF.TAC.TOTAL # view cumulative data table
tail(DF.TAC.TOTAL, n = 50)
# Analysis Steps
# 1. Merge output with ID references  --------------------------------------------------------------------------------------------------------- #
# 2. Seperate datasets into 'initial' and 'post' copper reaction ------------------------------------------------------------------------------ #
# 3. Obtain median (where applies) of all 'initial' reads prior to Copper rxn   --------------------------------------------------------------- #
# 4. Merge the two datasets to simplify the correction for initial reads (post - initial = diff)  --------------------------------------------- #
# 5. Seperate Standards - assign theoretical concentration values (from Oxiselect protocol) --------------------------------------------------- #
# 6. Calculate UAE and CRE (UAE using y=mx+b from standard curve AND CRE is UAE*2189)
# 7. Merge with the master sheet and correct for homogenate volume, afdw, and total protein
# 8. Run models for treatment effect(s)
# 1. ------------------------------------------------------------------------------------------------------------------------------------------ #
# merge with Reference and ommit NAs
TAC.MERGE.Reference <- merge(DF.TAC.TOTAL, TAC.Reference, by = c('Date','Run', 'Well')) # merge with the reference data
tail(TAC.MERGE.Reference, n = 50)
TAC.MERGE.Reference <- na.omit(TAC.MERGE.Reference) # ommit NAs
tail(TAC.MERGE.Reference, n = 50)
# 2 and 3. ------------------------------------------------------------------------------------------------------------------------------------ #
# INITIAL READS calculate median for duplicated values
INITIAL.Calc.DF <- TAC.MERGE.Reference %>%  dplyr::filter(Initial.Post %in% 'i')# %>%  # call only initial data
INITIAL.Calc.DF # view the table of mean values (actually the median of duplicates - prints the single value for readings not duplicated)
tail(INITIAL.Calc.DF, n = 50)
# POST READS (after the copper reaction)
POST.DF <- TAC.MERGE.Reference %>%  dplyr::filter(Initial.Post %in% 'p') # call only post data
tail(POST.DF, n = 50)
# 4. ------------------------------------------------------------------------------------------------------------------------------------------ #
# Merge the Initial with the Post data - initial medians will be duplicated where multiple reads were completed on the same individuals ID
MERGE.DF <- merge(INITIAL.Calc.DF, POST.DF, by = c("Date", "Well", "Run", "Reagent.Date", "Type"))
MERGE.DF$Absorbance.diff <- MERGE.DF$Absorbance.RAW.y - MERGE.DF$Absorbance.RAW.x
MERGE.DF.1 <- MERGE.DF %>% dplyr::filter(Run == 1)
run1less.than.stand <- MERGE.DF.1 %>%  dplyr::filter(Absorbance.diff < 0.03) # find the values that will be negative downstream (less absorbance than the standard at 0)
MERGE.DF.2 <- MERGE.DF %>% dplyr::filter(Run == 2)
run2less.than.stand <- MERGE.DF.2 %>%  dplyr::filter(Absorbance.diff < 0.03) # find the values that will be negative downstream (less absorbance than the standard at 0)
MERGE.DF.3 <- MERGE.DF %>% dplyr::filter(Run == 3)
run3less.than.stand <- MERGE.DF.3 %>%  dplyr::filter(Absorbance.diff < 0.03) # one negative value of -0.001 - make this zero in the following...
MERGE.DF$Absorbance.diff <- ifelse(MERGE.DF$Absorbance.diff < 0.0000, 0, MERGE.DF$Absorbance.diff) # make negative value ZERO (only one in the third run)
#MERGE.DF.d <-  MERGE.DF %>% dplyr::filter(ID.x == 1483)
# 5. ------------------------------------------------------------------------------------------------------------------------------------------ #
MASTER.TAC.DF <- MERGE.DF %>% dplyr::select(Date, Reagent.Date, ID.x, Type, Absorbance.diff) # select target columns
colnames(MASTER.TAC.DF)[3] <- "ID" # change column name to ID
# Standards
Stand.reference <- data.frame(matrix(nrow = 10, ncol = 2)) # create dataframe with 10 rwos (standards) and 2 columnds (ID and mM Uric Acid)
colnames(Stand.reference)<-c('ID', 'mM.Uric.Acid') # assign column names
Stand.reference$ID <- c("S.1","S.2","S.3","S.4","S.5","S.6","S.7","S.8","S.9","S.10") # assign IDs (must be the same format as IDs in reference csv file)
Stand.reference$mM.Uric.Acid <- c(1, 0.5, 0.25, 0.125, 0.0625, 0.03125, 0.0156, 0.0078, 0.0039, 0.0) # assign mM uric acid (Oxiselect protocol)
Standards <- MASTER.TAC.DF %>% dplyr::filter(Type %in% "Standard") # call all rows that are standards
Standards.Median <- Standards %>%
dplyr::group_by(Date, ID) %>% # call column to summarize
dplyr::summarise(Stand.ABS.median = mean(Absorbance.diff)) # call mean (median)
Standards.Median # view the table of mean values (actually the median of duplicates - all corrected for the median of the 'initial'
Standards.MASTER <- merge(Standards.Median, Stand.reference, by = "ID")
# NOTE: highest absorbance of standard 0.4925
# lowest standard absorbance is 0.0300
#Standards.MASTER.2 <- Standards.MASTER %>% filter(Stand.ABS.median > 0.0301) # remove the zero standard
#Standards.MASTER.2$Stand.ABS.median <- Standards.MASTER.2$Stand.ABS.median + 0.03 # add the absorbance of the zero standard to all other standards
# Note: this will give the accurate calculattion from the regression to calculation UAE based on all the data added by 0.03 (the zero standard absorbance)
# Standard Curves
# Standard curve - OCTOBER run
Standards.Oct <- Standards.MASTER %>% dplyr::filter(Date %in% '20191030')
Standards.model.Oct <-lm(Stand.ABS.median ~ mM.Uric.Acid, data=Standards.Oct) #runs a linear regression of mV as a function of temperature
plot(Stand.ABS.median ~ mM.Uric.Acid, data=Standards.Oct) # high standard is off
Standards.Oct.2 <- Standards.Oct %>% dplyr::filter(mM.Uric.Acid < 1.0) # remove the high standard for better fit
Standards.model.Oct.2 <-lm(Stand.ABS.median ~ mM.Uric.Acid, data=Standards.Oct.2) #runs a linear regression of mV as a function of temperature
plot(Stand.ABS.median ~ mM.Uric.Acid, data=Standards.Oct.2) # better  fit
summary(lm(Stand.ABS.median ~ mM.Uric.Acid, data=Standards.Oct.2)) # Adjusted R-squared:  0.9906
abline(lm(Stand.ABS.median ~ mM.Uric.Acid, data=Standards.Oct.2))
#b.Oct <- 0.03#summary(Standards.model)$coefficients[1]
b.Oct <- summary(Standards.model.Oct.2)$coefficients[1] # 0.03590498
m.Oct <- summary(Standards.model.Oct.2)$coefficients[2] # 0.5781389
R2.Oct<-summary(Standards.model.Oct.2)$r.squared # 0.9917731
legend('topleft', legend = bquote(R^2 == .(format(R2.Oct, digits = 3))), bty='n',)
# Standard curve - Dec run
Standards.Dec <- Standards.MASTER %>% dplyr::filter(Date %in% '20191210')
Standards.model.Dec <-lm(Stand.ABS.median ~ mM.Uric.Acid, data=Standards.Dec) #runs a linear regression of mV as a function of temperature
plot(Stand.ABS.median ~ mM.Uric.Acid, data=Standards.Dec) # high standard is off
abline(lm(Stand.ABS.median ~ mM.Uric.Acid, data=Standards.Dec))
summary(Standards.model.Dec) # 0.9991
b.Dec <- summary(Standards.model.Dec)$coefficients[1] # 0.03982677
m.Dec <- summary(Standards.model.Dec)$coefficients[2] # 1.272379
R2.Dec<-summary(Standards.model.Dec)$r.squared # 0.9991627
legend('topleft', legend = bquote(R^2 == .(format(R2.Dec, digits = 3))), bty='n',)
# 6. ------------------------------------------------------------------------------------------------------------------------------------------ #
# Master Data Frame
zero.standards <- Standards.MASTER %>%  filter(mM.Uric.Acid == 0) # 0.0300 and 0.0335
MASTER.TAC.DF.Oct <- MASTER.TAC.DF %>%  filter(Date == 20191030) # october samples
MASTER.TAC.DF.Oct$zero.stand <- 0.0300
MASTER.TAC.DF.Dec <- MASTER.TAC.DF %>%  filter(Date %in% c('20191210', '20191212')) # december samples
MASTER.TAC.DF.Dec$zero.stand <- 0.0335
MASTER.TAC.DF.2 <- rbind(MASTER.TAC.DF.Oct, MASTER.TAC.DF.Dec)
MASTER.TAC.DF.2$Absorbance.diff.add.zero.stand <- MASTER.TAC.DF.2$Absorbance.diff + MASTER.TAC.DF.2$zero.stand # new column add the ZERO absorbance of the standard at zero
MASTER.TAC.DF.means <- MASTER.TAC.DF.2 %>% group_by(Date,ID,Type) %>%
dplyr::summarise(Absorbance.mean = mean(Absorbance.diff.add.zero.stand))# summarize data table of the mean values for the absorbance corrected for the zero standard
# remove standards from data, Calculate UAE and CRE
MASTER.TAC.DF.SAMPLES <- MASTER.TAC.DF.means %>% dplyr::filter(!Type == "Standard") # remove standards
SAMPLES.under.standards <- MASTER.TAC.DF.SAMPLES %>% dplyr::filter(Absorbance.mean < 0.0300)
MASTER.TAC.DF.SAMPLES.Oct <- MASTER.TAC.DF.SAMPLES %>%  filter(Date == 20191030) # october samples
#MASTER.TAC.DF.SAMPLES.Oct$mM.Uric.Acid.Equivalents <- (MASTER.TAC.DF.SAMPLES.Oct$Absorbance.mean - b.Oct)/m.Oct # Calculate URIC ACID EQUIVALENTS (UAE) - weighed low mass of Cu standard - may have confoundded our calib curve
MASTER.TAC.DF.SAMPLES.Oct$mM.Uric.Acid.Equivalents <- (MASTER.TAC.DF.SAMPLES.Oct$Absorbance.mean - b.Dec)/m.Dec # based on calibration curve in december run Calculate URIC ACID EQUIVALENTS (UAE)
MASTER.TAC.DF.SAMPLES.Dec  <- MASTER.TAC.DF.SAMPLES %>%  filter(Date %in% c('20191210', '20191212')) # december samples
MASTER.TAC.DF.SAMPLES.Dec$mM.Uric.Acid.Equivalents <- (MASTER.TAC.DF.SAMPLES.Dec$Absorbance.mean - b.Dec)/m.Dec # Calculate URIC ACID EQUIVALENTS (UAE)
MASTER.TAC.DF.SAMPLES.2 <- rbind(MASTER.TAC.DF.SAMPLES.Oct, MASTER.TAC.DF.SAMPLES.Dec)
plot(Absorbance.mean ~ mM.Uric.Acid.Equivalents, data=MASTER.TAC.DF.SAMPLES.2) # plot the data
summary(lm(Absorbance.mean ~ mM.Uric.Acid.Equivalents, data=MASTER.TAC.DF.SAMPLES.2))
MASTER.TAC.DF.SAMPLES.2$µM.Copper.Reducing.Equivalents <- MASTER.TAC.DF.SAMPLES.2$mM.Uric.Acid.Equivalents*2189 # Calculate µM Copper Reducing Equivlents (CRE)
# Summarize by ID to obtain the median (assay completed in duplicates)
MASTER.TAC.MEANS <- MASTER.TAC.DF.SAMPLES.2 %>%
dplyr::group_by(Date, ID) %>% # call column to summarize
dplyr::summarise(mean.UAE = mean(mM.Uric.Acid.Equivalents),
mean.CRE = mean(µM.Copper.Reducing.Equivalents))
MASTER.TAC.MEANS # view the table of mean values (actually the median of duplicates - prints the single value for readings not duplicated)
tail(MASTER.TAC.MEANS)
################################################################################################################################## #
################################################################################################################################## #
###############################################################  MERGE FOR FINAL DATASET  ##########################################
################################################################### OXISELECT ASSSAY     ######################################### #
################################################################################################################################## #
MASTER.TAC.MEANS # calculated total antioxidant capacity
sum(complete.cases(MASTER.TAC.MEANS)) # 144 - still have ~ 20 samples to run
MASTER.TP.MEANS # calculated total antioxidant capacity
sum(complete.cases(MASTER.TP.MEANS)) # 161 - three less than total master sheet due to bad spec measurements
Master.Sample.Tracker # master sheet of all data (total homogenized volume, AFDW, volumes for each assay, dolution information, etc.)
sum(complete.cases(Master.Sample.Tracker$ID))  # 164
# Merge with the master sheet (containing Treatment IDs and Correction factors)
TAC.TP.MERGE <- merge(MASTER.TP.MEANS, MASTER.TAC.MEANS, by = 'ID')
Master.Sample.Tracker$ID <- Master.Sample.Tracker$NEW.Tube.ID
MASTER.PHYS.ASSAY <- merge(TAC.TP.MERGE, Master.Sample.Tracker, by = 'ID')
# correct for homogenate volume as "TOTAL"
# TOTAL.total.protein mg/mL - (total homogenate vol / vol aliquot for protein assay) * (protein measured in aliquot*dilution factor)
sapply(MASTER.PHYS.ASSAY, class) # check the class - occasionally variables that are numeric are characters
MASTER.PHYS.ASSAY$µl.Total.Homog.Volume <- as.numeric(MASTER.PHYS.ASSAY$µl.Total.Homog.Volume) # convert to numeric
MASTER.PHYS.ASSAY$µl.Total.protein  <- as.numeric(MASTER.PHYS.ASSAY$µl.Total.protein)  # convert to numeric
MASTER.PHYS.ASSAY$mean.mg.mL_BCA # = mg / ml raw signal from the calibration curve;
MASTER.PHYS.ASSAY$TOTAL_PROTEIN_per_well_corrected <- (MASTER.PHYS.ASSAY$mean.mg.mL_BCA*MASTER.PHYS.ASSAY$Dil.factor.Total.Protein) # mg  protein ONLY IN THE 20ul sample (account for dilution from NaOH and HCl; 20 ul used for the Rapid Gold assay
# NOTE: TOTAL_PROTEIN_per_SAMPLE is the mg of protein in the 20 µl sample for the rapid gold assay kit
# TOTAL.mean.CRE - µm cOPPER reDUCING eQUIVALENTS MG PROTEIN -1 (IN THE 20 UL SAMPLE)
#MASTER.PHYS.ASSAY$µl.TAC <- as.numeric(MASTER.PHYS.ASSAY$µl.TAC) # convert to numericvolume aliquot (~50 - 100 ul; in spreadsheet) from total homogenate volume (HV = PBS + whole geoduck)
MASTER.PHYS.ASSAY$mean.CRE <- as.numeric(MASTER.PHYS.ASSAY$mean.CRE) # uM concentration NOT DILUTED convert to numeric
MASTER.PHYS.ASSAY$Dil.factor.TAC <- as.numeric(MASTER.PHYS.ASSAY$Dil.factor.TAC) # convert to numeric dilution factor for a few samples that were additionally diluted prior to NaOH and HCl
MASTER.PHYS.ASSAY$µM.CRE.mg.protein<- (MASTER.PHYS.ASSAY$mean.CRE*MASTER.PHYS.ASSAY$Dil.factor.TAC) / (MASTER.PHYS.ASSAY$TOTAL_PROTEIN_per_well_corrected) # µM CRE mg protein = concentration of CRE in the 20 µl sample / protein in 20 ul sample
# Total protein WHOLE ANIMALS corrected for AFDW (AS mgProtein.mgAFDW)
MASTER.PHYS.ASSAY$TOTAL.PROTEIN_whole.animal.mg <- (MASTER.PHYS.ASSAY$µl.Total.Homog.Volume/20)*MASTER.PHYS.ASSAY$TOTAL_PROTEIN_per_well_corrected
MASTER.PHYS.ASSAY$mgProtein.mgAFDW <- MASTER.PHYS.ASSAY$TOTAL.PROTEIN_whole.animal.mg /  MASTER.PHYS.ASSAY$mgTOTAL_AFDW
PHYS.DATA <- MASTER.PHYS.ASSAY %>% dplyr::select(Date.fixed, ID, Treatment, Exprmt.Day, Tank.ID,
mgTOTAL_AFDW,
mgProtein.mgAFDW,
µM.CRE.mg.protein)
PHYS.DATA
# write out tables
write.table(PHYS.DATA, file="C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Output/Phys.Assay.Table.csv", sep=",", row.names = FALSE) #save data to output file
Calls the Table (From Phys_Calc.R, output as "Phys.Assay.Table.csv")
#See Readme file for details
rm(list=ls())
# Install packages if not already in your library-----------------------------------------------------------------------------------------------
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
if ("lsmeans" %in% rownames(installed.packages()) == 'FALSE') install.packages('lsmeans')
if ("ggpubr" %in% rownames(installed.packages()) == 'FALSE') install.packages('ggpubr')
# Load packages and pacage version/date/import/depends info
library(dplyr) # Version 0.7.6, Packaged: 2018-06-27, Depends: R (>= 3.1.2)Imports: assertthat (>= 0.2.0), bindrcpp (>= 0.2.0.9000), glue (>=1.1.1), magrittr (>= 1.5), methods, pkgconfig (>= 2.0.1), R6(>= 2.2.2), Rcpp (>= 0.12.15), rlang (>= 0.2.0), tibble (>=1.3.1), tidyselect (>= 0.2.3), utils
library(lsmeans) # Version: 2.27-62, Date/Publication: 2018-05-11, Depends: methods, R (>= 3.2)
library(ggpubr)
#set working directory--------------------------------------------------------------------------------------------------------------------------
setwd("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis") #set working
# NOTE: This script analyzes a subsample of the significant effect(s) found for Resp rate (review /Scripts/Resp.Analysis.R)
# and analyzes the first run of phys assays of 84 chosen samples TARGETTED to these significant effects of treatment on respiration rate
# Resp rate effects on....
# Days 1 - 7: Effect of initial exposure × history - EHM and AHM -  resp rate marginal difference with greater rates
# Days 15 - 21: Effect of initial exposure × history;  EHS and EHA - resp rate significant difference with greater rates in EHS
# Review the following
#  ASSEMBLE ALL DATA FOR GRAPHS AND ANALYSIS ------------------------------------- #
# Total antioxidant capacity, total protein and ARDW data
PHYS.DATA <- read.csv(file="Output/Phys.Assay.Table.csv", header=T) #read PPhys assay data output from Phys_Calc.R (TAC, TP, AFDW of targetted samples)
# Respiration rate data
resp.data <- read.csv(file="Data/SDR_data/Final_table_for_resp_analysis.csv", header=T) #read Size.info resp.data
resp.data.Days.1.7 <- resp.data %>% dplyr::filter(Date %in% 20190725:20190731) %>% dplyr::select(Date, resp.COUNT.µg.L.hr.indiv,resp.MEAN.µg.L.hr.mm, Treatment.EXP_1, Treatment.history) # d 1 - 7 experiment
resp.data_Days.8.14 <- resp.data %>% dplyr::filter(Date %in% 20190801:20190807) %>% dplyr::select(Date, resp.COUNT.µg.L.hr.indiv,resp.MEAN.µg.L.hr.mm, Treatment.EXP_1, Treatment.history) # d 8 - 14 experiment
resp.data_Days.15.21 <- resp.data %>% dplyr::filter(Date %in% 20190808:20190814) %>% dplyr::select(Date, resp.COUNT.µg.L.hr.indiv,resp.MEAN.µg.L.hr.mm, Treatment.EXP_2, Treatment.history, Treatment.EXP_1) # d 15-21 experiment
################################################################ #
################################################################ #
################################################################ #
######     DAY 1 -7 initial exposure × history       ###########
##########       RESP RATES EHM > AHM  ######################### #
################################################################ #
################################################################ #
#initial effect
Model_1_RESP.rate <- aov(resp.MEAN.µg.L.hr.mm~Treatment.history*Treatment.EXP_1*Date, data = resp.data.Days.1.7) # run model
summary(Model_1_RESP.rate)
shapiro.test(residuals(Model_1_RESP.rate)) # p-value = 0.2751; normal via shapiro wilk test
hist((residuals(Model_1_RESP.rate))) # histogram of residuals
qqnorm(residuals(Model_1_RESP.rate)) # qqplot
# post-hoc
Model_1_RESP.rate.MEANS <- lsmeans(Model_1_RESP.rate, pairwise ~  Treatment.history:Treatment.EXP_1)# pariwise Tukey Post-hoc test between repeated treatments
# AH,M - EH,M -1.07408508 0.3831895 98  -2.803  0.0654 MARGINAL DIFF BETWEEN AHM AND EHM
resp.data.Days.1.7$Treatment.initial <- paste(resp.data.Days.1.7$Treatment.history, resp.data.Days.1.7$Treatment.EXP_1, sep="")
resp.data.Days.1.7.EFFECT <- resp.data.Days.1.7 %>%  dplyr::filter(Treatment.initial %in% c("EHM", "AHM"))
plot_initial.resp <- ggviolin(resp.data.Days.1.7.EFFECT, ylab =expression("Respiration rate"~(~µg~O[2]*hr^{-1}*indiv^{-1})),
x = "Treatment.initial", y = "resp.COUNT.µg.L.hr.indiv",  fill = "Treatment.initial",
palette = c("#FC4E07", "#00AFBB"), add = "none", title = "Respiration rate")
plot_initial.resp
# INITIAL EFFECT - Marginal diff in metabolic response EHM > AHM during initial subseq exposure (Days 1 4 7)
# prep the data
Data.D.1.4.7 <- PHYS.DATA %>% dplyr::filter(Date.fixed < 20190801) # call data by DATE for the correct timeline
Data.D.1.4.7$Treatment <- factor(Data.D.1.4.7$Treatment, levels = c("EHM","AHM"))
count <- Data.D.1.4.7 %>%  dplyr::group_by(Treatment) %>% dplyr::summarise(count = n()) # 18 (AHM) and 17 (EHM) look at the count of replicates per day (removed NAs due to testing, under pipetting, and spec errors)
# ASH FREE DRY WEIGHT
Model_1_AFDW <- aov(mgTOTAL_AFDW~Treatment*Exprmt.Day, data = Data.D.1.4.7) # run model
summary(Model_1_AFDW)
resp.data.Days.1.7
Data.D.7
# INITIAL EFFECT - Day 7
Data.D.7 <- PHYS.DATA %>% dplyr::filter(Date.fixed == '20190731')
Data.D.7$Treat_history <- substr(Data.D.7$Treatment, 1,1)
Data.D.7$initial <- substr(Data.D.7$Treatment, 3,3)
Data.D.7 <- Data.D.7 %>% filter(µM.CRE.mg.protein > 0) # ommit values below 0
Data.D.7
Data.D.7
# AFDW
model_Day7_AFDW <- aov(mgProtein.mgAFDW  ~ Treat_history * initial, data = Data.D.7)
summary(model_Day7_AFDW)
shapiro.test(residuals(model_Day7_AFDW)) # p-value = 0.0003713; non normal via shapiro wilk test - likely due to single outlier
shapiro.test(residuals(model_Day7_AFDW)) # p-value = 0.5455; normal via shapiro wilk test
hist((residuals(model_Day7_AFDW))) # histogram of residuals
qqnorm(residuals(model_Day7_AFDW)) # qqplot
D.7.PLOTbox.Protein<- ggboxplot(Data.D.7, x = "initial", y = "mgProtein.mgAFDW",  ylab = "mgProtein.mgAFDW",  fill = "Treat_history",
palette = c("#FC4E07", "#00AFBB"),add = "jitter", title = "Secondary TAOC")
D.7.PLOTbox.Protein <- ggpar(D.7.PLOTbox.Protein, ylim = c(0,200))
D.7.PLOTbox.Protein
D.21.PLOTbox<- ggboxplot(Data.D.21, x = "secondary", y = "µM.CRE.mg.protein",  ylab = "µM.CRE.mg.protein",  fill = "Treat_history",
palette = c("#FC4E07", "#00AFBB"),add = "jitter", shape = "tertiary", title = "Tertiary TAOC")
D.21.PLOTbox <- ggpar(D.21.PLOTbox, ylim = c(25,150))
D.21.PLOTbox<- ggboxplot(Data.D.21, x = "secondary", y = "µM.CRE.mg.protein",  ylab = "µM.CRE.mg.protein",  fill = "Treat_history",
palette = c("#FC4E07", "#00AFBB"),add = "jitter", shape = "tertiary", title = "Tertiary TAOC")
D.21.PLOTbox <- ggpar(D.21.PLOTbox, ylim = c(25,150))
D.21.PLOTbox
D.21.PLOTbox<- ggboxplot(Data.D.21, x = "secondary", y = "µM.CRE.mg.protein",  ylab = "µM.CRE.mg.protein",  fill = "Treat_history",
palette = c("#FC4E07", "#00AFBB"),add = "jitter", shape = "tertiary", title = "Tertiary TAOC")
D.21.PLOTbox <- ggpar(D.21.PLOTbox, ylim = c(25,150))
D.21.PLOTbox
#Author: Sam Gurr
#Edited by: Sam Gurr
#Date Last Modified: 20191107
#Purpose: Calls the Table (From Phys_Calc.R, output as "Phys.Assay.Table.csv")
#See Readme file for details
rm(list=ls())
# Install packages if not already in your library-----------------------------------------------------------------------------------------------
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
if ("lsmeans" %in% rownames(installed.packages()) == 'FALSE') install.packages('lsmeans')
if ("ggpubr" %in% rownames(installed.packages()) == 'FALSE') install.packages('ggpubr')
# Load packages and pacage version/date/import/depends info
library(dplyr) # Version 0.7.6, Packaged: 2018-06-27, Depends: R (>= 3.1.2)Imports: assertthat (>= 0.2.0), bindrcpp (>= 0.2.0.9000), glue (>=1.1.1), magrittr (>= 1.5), methods, pkgconfig (>= 2.0.1), R6(>= 2.2.2), Rcpp (>= 0.12.15), rlang (>= 0.2.0), tibble (>=1.3.1), tidyselect (>= 0.2.3), utils
library(lsmeans) # Version: 2.27-62, Date/Publication: 2018-05-11, Depends: methods, R (>= 3.2)
library(ggpubr)
#set working directory--------------------------------------------------------------------------------------------------------------------------
setwd("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis") #set working
# NOTE: This script analyzes a subsample of the significant effect(s) found for Resp rate (review /Scripts/Resp.Analysis.R)
# and analyzes the first run of phys assays of 84 chosen samples TARGETTED to these significant effects of treatment on respiration rate
# Resp rate effects on....
# Days 1 - 7: Effect of initial exposure × history - EHM and AHM -  resp rate marginal difference with greater rates
# Days 15 - 21: Effect of initial exposure × history;  EHS and EHA - resp rate significant difference with greater rates in EHS
# Review the following
#  ASSEMBLE ALL DATA FOR GRAPHS AND ANALYSIS ------------------------------------- #
# Total antioxidant capacity, total protein and ARDW data
PHYS.DATA <- read.csv(file="Output/Phys.Assay.Table.csv", header=T) #read PPhys assay data output from Phys_Calc.R (TAC, TP, AFDW of targetted samples)
# Respiration rate data
resp.data <- read.csv(file="Data/SDR_data/Final_table_for_resp_analysis.csv", header=T) #read Size.info resp.data
resp.data.Days.1.7 <- resp.data %>% dplyr::filter(Date %in% 20190725:20190731) %>% dplyr::select(Date, resp.COUNT.µg.L.hr.indiv,resp.MEAN.µg.L.hr.mm, Treatment.EXP_1, Treatment.history) # d 1 - 7 experiment
resp.data_Days.8.14 <- resp.data %>% dplyr::filter(Date %in% 20190801:20190807) %>% dplyr::select(Date, resp.COUNT.µg.L.hr.indiv,resp.MEAN.µg.L.hr.mm, Treatment.EXP_1, Treatment.history) # d 8 - 14 experiment
resp.data_Days.15.21 <- resp.data %>% dplyr::filter(Date %in% 20190808:20190814) %>% dplyr::select(Date, resp.COUNT.µg.L.hr.indiv,resp.MEAN.µg.L.hr.mm, Treatment.EXP_2, Treatment.history, Treatment.EXP_1) # d 15-21 experiment
################################################################ #
################################################################ #
################################################################ #
######     DAY 1 -7 initial exposure × history       ###########
##########       RESP RATES EHM > AHM  ######################### #
################################################################ #
################################################################ #
#initial effect
Model_1_RESP.rate <- aov(resp.MEAN.µg.L.hr.mm~Treatment.history*Treatment.EXP_1*Date, data = resp.data.Days.1.7) # run model
summary(Model_1_RESP.rate)
shapiro.test(residuals(Model_1_RESP.rate)) # p-value = 0.2751; normal via shapiro wilk test
hist((residuals(Model_1_RESP.rate))) # histogram of residuals
qqnorm(residuals(Model_1_RESP.rate)) # qqplot
# post-hoc
Model_1_RESP.rate.MEANS <- lsmeans(Model_1_RESP.rate, pairwise ~  Treatment.history:Treatment.EXP_1)# pariwise Tukey Post-hoc test between repeated treatments
# AH,M - EH,M -1.07408508 0.3831895 98  -2.803  0.0654 MARGINAL DIFF BETWEEN AHM AND EHM
resp.data.Days.1.7$Treatment.initial <- paste(resp.data.Days.1.7$Treatment.history, resp.data.Days.1.7$Treatment.EXP_1, sep="")
resp.data.Days.1.7.EFFECT <- resp.data.Days.1.7 %>%  dplyr::filter(Treatment.initial %in% c("EHM", "AHM"))
plot_initial.resp <- ggviolin(resp.data.Days.1.7.EFFECT, ylab =expression("Respiration rate"~(~µg~O[2]*hr^{-1}*indiv^{-1})),
x = "Treatment.initial", y = "resp.COUNT.µg.L.hr.indiv",  fill = "Treatment.initial",
palette = c("#FC4E07", "#00AFBB"), add = "none", title = "Respiration rate")
plot_initial.resp
# stat.test.RESP<- compare_means(
# resp.MEAN.µg.L.hr.mm~Treatment.initial, data = resp.data.Days.1.7.EFFECT,
# method = "t.test")
# stat.test.RESP <- stat.test.RESP %>%# Add manually p-values from stat.test data
# Insert the results of the tukey test in the Resp.Analysis.R Script
# result from three way anova history × exposure = p = 0.0647; tukey test EH:M > AH:M p = 0.0408
threewayanova.resp.table <- data.frame(matrix(nrow = 1, ncol = 4))
colnames(threewayanova.resp.table)<-c('test', 'group1', 'group2', 'p-val_tukey') # column names, matches all data
threewayanova.resp.table[1,] <- c("initial", "EHM", "AHM", 0.0408)
threewayanova.resp.table <- threewayanova.resp.table %>%# Add manually p-values from stat.test data
mutate(y.position = c(22))
plot_initial.resp <- plot_initial.resp %>% ggadd(c("boxplot", "jitter"), fill = "white")  +
stat_pvalue_manual(threewayanova.resp.table, label ="p-val_tukey") # Add box plot
plot_initial.resp <- ggpar(plot_initial.resp, ylim = c(0,35))
plot_initial.resp
# INITIAL EFFECT - Day 7
Data.D.7 <- PHYS.DATA %>% dplyr::filter(Date.fixed == '20190731')
Data.D.7$Treat_history <- substr(Data.D.7$Treatment, 1,1)
Data.D.7$initial <- substr(Data.D.7$Treatment, 3,3)
Data.D.7 <- Data.D.7 %>% filter(µM.CRE.mg.protein > 0) # ommit values below 0
# DAY 7 TEST
# TAC
model_Day7_TAC <- aov(µM.CRE.mg.protein ~ Treat_history * initial, data = Data.D.7)
summary(model_Day7_TAC)
shapiro.test(residuals(model_Day7_TAC)) # p-value = 0.0003713; non normal via shapiro wilk test - likely due to single outlier
hist((residuals(model_Day7_TAC))) # histogram of residuals
qqnorm(residuals(model_Day7_TAC)) # qqplot
outliers <- boxplot(Data.D.7$µM.CRE.mg.protein , plot=FALSE)$out # id the outlier
print(outliers) # view the outlier
Data.D.7.OM <- Data.D.7[-which(Data.D.7$µM.CRE.mg.protein %in% outliers),] # remove outlier from new data frame
model_Day7_TAC.OM<- aov(µM.CRE.mg.protein ~ Treat_history * initial, data = Data.D.7.OM) # run the model without the outlier
summary(model_Day7_TAC.OM) # view model - no significant diffs
shapiro.test(residuals(model_Day7_TAC.OM)) # p-value = 0.8191; normal via shapiro wilk test
hist((residuals(model_Day7_TAC.OM))) # histogram of residuals
qqnorm(residuals(model_Day7_TAC.OM)) # qqplot
Data.D.7$Treat <- substr(DATA.pre$Treatment.history, 1,1)
D.7.PLOTbox<- ggboxplot(Data.D.7, x = "initial", y = "µM.CRE.mg.protein",  ylab = "µM.CRE.mg.protein",  fill = "Treat_history",
palette = c("#FC4E07", "#00AFBB"),add = "jitter", title = "Secondary TAOC")
D.7.PLOTbox <- ggpar(D.7.PLOTbox, ylim = c(0,200))
D.7.PLOTbox
# .Protein
model_Day7_AFDW <- aov(mgProtein.mgAFDW  ~ Treat_history * initial, data = Data.D.7)
summary(model_Day7_AFDW)
shapiro.test(residuals(model_Day7_AFDW)) # p-value = 0.5455; normal via shapiro wilk test
hist((residuals(model_Day7_AFDW))) # histogram of residuals
qqnorm(residuals(model_Day7_AFDW)) # qqplot
D.7.PLOTbox.Protein<- ggboxplot(Data.D.7, x = "initial", y = "mgProtein.mgAFDW",  ylab = "mgProtein.mgAFDW",  fill = "Treat_history",
palette = c("#FC4E07", "#00AFBB"),add = "jitter", title = "Secondary TAOC")
D.7.PLOTbox.Protein <- ggpar(D.7.PLOTbox.Protein, ylim = c(0,200))
D.7.PLOTbox.Protein
#DAY 21 TEST
Data.D.21 <- PHYS.DATA %>% dplyr::filter(Date.fixed == '20190814')
Data.D.21 <- Data.D.21 %>% filter(µM.CRE.mg.protein > 0) # ommit values below 0
Data.D.21$µM.CRE.mg.protein <- ifelse(Data.D.21$µM.CRE.mg.protein  < 0.0000, 0, Data.D.21$µM.CRE.mg.protein ) # values < 0 make 0
Data.D.21$Treat_history <- substr(Data.D.21$Treatment, 1,1)
Data.D.21$secondary <- substr(Data.D.21$Treatment, 3,3)
Data.D.21$tertiary <- substr(Data.D.21$Treatment, 4,4)
count.treat <- Data.D.21 %>%  dplyr::group_by(Treatment) %>%
dplyr::summarise(count_replicated.by.day =n())
count.treat # STILL NEED TO ANALYZE SOME SAMPLES
model_Day21_TAC <- aov(µM.CRE.mg.protein ~ Treat_history * secondary * tertiary, data = Data.D.21)
summary(model_Day21_TAC) # marginal difference due to treatment history
shapiro.test(residuals(model_Day21_TAC)) # p-value = 0.001127; non normal via shapiro wilk test
hist((residuals(model_Day21_TAC))) # histogram of residuals - LEFT SKEW - LOG TRANSFORM
qqnorm(residuals(model_Day21_TAC)) # qqplot
model_Day21_TAC <- aov((log(µM.CRE.mg.protein)) ~ Treat_history * secondary * tertiary, data = Data.D.21)
summary(model_Day21_TAC) # transformed data shows a significant difference due to treatment history
TukeyHSD(model_Day21_TAC) # E-A -0.1991035 -0.3751744 -0.02303262 0.0278336
shapiro.test(residuals(model_Day21_TAC)) # p-value = 0.7787; non normal via shapiro wilk test
hist((residuals(model_Day21_TAC))) # histogram of residuals - GOOD
qqnorm(residuals(model_Day21_TAC)) # qqplot - GOOD
plot.DAY21.TAC <- ggviolin(Data.D.21, x = "Treat_history", y = "µM.CRE.mg.protein",  ylab = "µM.CRE.mg.protein", fill = "Treat_history",
palette = "rickandmorty", add = "none",  title ="TAC_DAY_21")
plot.DAY21.TAC %>% ggadd(c("boxplot", "jitter"), color = "Treat_history")
plot.DAY21.TAC <- plot.DAY21.TAC %>% ggadd(c("boxplot", "jitter"), fill = "white")
#plot.DAY21.TAC <- ggpar(plot.DAY21.TAC, ylim =c(-2,20))
plot.DAY21.TAC # VIEW PLOT
D.21.PLOTbox<- ggboxplot(Data.D.21, x = "secondary", y = "µM.CRE.mg.protein",  ylab = "µM.CRE.mg.protein",  fill = "Treat_history",
palette = c("#FC4E07", "#00AFBB"),add = "jitter", shape = "tertiary", title = "Tertiary TAOC")
D.21.PLOTbox <- ggpar(D.21.PLOTbox, ylim = c(25,150))
D.21.PLOTbox
D.7.PLOTbox.Protein
D.7.PLOTbox.Protein <- ggpar(D.7.PLOTbox.Protein, ylim = c(0,35))
D.7.PLOTbox.Protein
D.7.PLOTbox.Protein<- ggboxplot(Data.D.7, x = "initial", y = "mgProtein.mgAFDW",  ylab = "mgProtein.mgAFDW",  fill = "Treat_history",
palette = c("#FC4E07", "#00AFBB"),add = "jitter", title = "Secondary TAOC")
D.7.PLOTbox.Protein <- ggpar(D.7.PLOTbox.Protein, ylim = c(0,35))
D.7.PLOTbox.Protein
# .Protein
model_Day7_AFDW <- aov(mgProtein.mgAFDW  ~ Treat_history * initial, data = Data.D.7)
summary(model_Day7_AFDW)
shapiro.test(residuals(model_Day7_AFDW)) # p-value = 0.5455; normal via shapiro wilk test
hist((residuals(model_Day7_AFDW))) # histogram of residuals
qqnorm(residuals(model_Day7_AFDW)) # qqplot
D.7.PLOTbox.Protein<- ggboxplot(Data.D.7, x = "initial", y = "mgProtein.mgAFDW",  ylab = "mgProtein.mgAFDW",  fill = "Treat_history",
palette = c("#FC4E07", "#00AFBB"),add = "jitter", title = "Secondary TAOC")
D.7.PLOTbox.Protein <- ggpar(D.7.PLOTbox.Protein, ylim = c(0,35))
D.7.PLOTbox.Protein
# .Protein
model_Day21_Proetin <- aov(mgProtein.mgAFDW  ~ Treat_history * initial, data = Data.D.21)
summary(model_Day21_Proetin)
#DAY 21 TEST
Data.D.21 <- PHYS.DATA %>% dplyr::filter(Date.fixed == '20190814')
Data.D.21 <- Data.D.21 %>% filter(µM.CRE.mg.protein > 0) # ommit values below 0
Data.D.21$µM.CRE.mg.protein <- ifelse(Data.D.21$µM.CRE.mg.protein  < 0.0000, 0, Data.D.21$µM.CRE.mg.protein ) # values < 0 make 0
Data.D.21$Treat_history <- substr(Data.D.21$Treatment, 1,1)
Data.D.21$secondary <- substr(Data.D.21$Treatment, 3,3)
Data.D.21$tertiary <- substr(Data.D.21$Treatment, 4,4)
# .Protein
model_Day21_Protein <- aov(mgProtein.mgAFDW  ~ Treat_history * initial, data = Data.D.21)
# .Protein
model_Day21_Protein <- aov(mgProtein.mgAFDW  ~ Treat_history * secondary * tertiary, data = Data.D.21)
summary(model_Day21_Proetin)
# .Protein
model_Day21_Protein <- aov(mgProtein.mgAFDW  ~ Treat_history * secondary * tertiary, data = Data.D.21)
summary(model_Day21_Protein)
shapiro.test(residuals(model_Day21_Protein)) # p-value = 0.5455; normal via shapiro wilk test
hist((residuals(model_Day21_Protein))) # histogram of residuals
hist((residuals(model_Day21_Protein))) # histogram of residuals left skew
qqnorm(residuals(model_Day21_Protein)) # qqplot
model_Day21_Protein.LOG <- aov((log(mgProtein.mgAFDW))  ~ Treat_history * secondary * tertiary, data = Data.D.21)
summary(model_Day21_Protein.LOG)
shapiro.test(residuals(model_Day21_Protein.LOG)) # p-value = 1e-06; non normal via shapiro wilk test
model_Day21_Protein.LOG <- aov((sqrt(mgProtein.mgAFDW))  ~ Treat_history * secondary * tertiary, data = Data.D.21)
summary(model_Day21_Protein.LOG)
shapiro.test(residuals(model_Day21_Protein.LOG)) # p-value = 1e-06; non normal via shapiro wilk test
model_Day21_Protein.LOG <- aov(((mgProtein.mgAFDW)^1/3)  ~ Treat_history * secondary * tertiary, data = Data.D.21)
summary(model_Day21_Protein.LOG)
shapiro.test(residuals(model_Day21_Protein.LOG)) # p-value = 1e-06; non normal via shapiro wilk test
model_Day21_Protein.LOG <- aov((log(mgProtein.mgAFDW))  ~ Treat_history * secondary * tertiary, data = Data.D.21)
summary(model_Day21_Protein.LOG)
shapiro.test(residuals(model_Day21_Protein.LOG)) # p-value = 1e-06; non normal via shapiro wilk test
shapiro.test(residuals(model_Day21_Protein.LOG)) # p-value = 0.04893; non normal via shapiro wilk test
hist((residuals(model_Day21_Protein.LOG))) # histogram of residuals left skew
qqnorm(residuals(model_Day21_Protein.LOG)) # qqplot
D.21.PLOTbox.Protein<- ggboxplot(Data.D.7, x = "secondary", y = "mgProtein.mgAFDW",  ylab = "mgProtein.mgAFDW",  fill = "Treat_history",
palette = c("#FC4E07", "#00AFBB"),add = "jitter", title = "tertiary TAOC")
D.21.PLOTbox.Protein<- ggboxplot(Data.D.21, x = "secondary", y = "mgProtein.mgAFDW",  ylab = "mgProtein.mgAFDW",  fill = "Treat_history",
palette = c("#FC4E07", "#00AFBB"),add = "jitter",shape = "tertiary", title = "tertiary TAOC")
D.21.PLOTbox.Protein <- ggpar(D.21.PLOTbox.Protein, ylim = c(0,35))
D.21.PLOTbox.Protein
outliers.d21_protein <- boxplot(Data.D.21$mgProtein.mgAFDW , plot=FALSE)$out # id the outlier
print(outliers.d21_protein) # view the outlier
