library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=190722&days=14") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
head(Apex.Data) # check the first few lines to see the first few hrs of the extracted data
tail(Apex.Data) # check to end to dertmine if the xmlParse extracted up to present day
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=190722&days=14") #read in the date plus x days of Apex data
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=190722&days=14") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
head(Apex.Data) # check the first few lines to see the first few hrs of the extracted data
tail(Apex.Data) # check to end to dertmine if the xmlParse extracted up to present day
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
tail(Apex.Data2) # check most recent data
names(Apex.Data2)
# Column names modified as of 20190220 - new apex (from broodstock set-up) moved to conicals due to a malfunction
# Date.Time = column 3
# TMP_T0 = column 6
# pH_T0= column 9
# TMP_T4 = column 69
# pH_T4 = column 72
# TMP_T6 = column 75
# pH_T6 = column 78
# TMP_T5 = column 81
# pH_T5 = column 84
# TMP_T1 = column 87
# pH_T1 = column 90
# TMP_T7 = column 93
# pH_T7 = column 96
# TMP_T3 = column 99
# pH_T3 = column 102
# TMP_T2 = column 105
# pH_T2 = column 108 pH_T2
# NOTE: 18 in total above
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,69,72,75,78,81,84,87,90,93,96,99,102,105,108)] #select columns
colnames(Probe.Data) <- c("Date.Time", "TMP_T0", "pH_T0", "TMP_T4", "pH_T4", "TMP_T6","pH_T6",
"TMP_T5", "pH_T5", "TMP_T1", "pH_T1", "TMP_T7", "pH_T7", "TMP_T3",
"pH_T3", "TMP_T2", "pH_T2")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
# tail(Probe.Data) # to view the newest data and compare to APEX fusion for assigning column names
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Output/20190805_Apex_Data_Output.data.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Graphs/20190805_Apex_Data_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(10, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(3.5, 8.5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Graphs/20190805_Apex_Data_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(15, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(6, 8.5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
ed reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=190809&days=7") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
head(Apex.Data) # check the first few lines to see the first few hrs of the extracted data
tail(Apex.Data) # check to end to dertmine if the xmlParse extracted up to present day
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
tail(Apex.Data2) # check most recent data
names(Apex.Data2)
tail(Apex.Data2) # check most recent data
# Column names modified as of 20190220 - new apex (from broodstock set-up) moved to conicals due to a malfunction
# Date.Time = column 3
# TMP_T0 = column 6
# pH_T0= column 9
# TMP_T4 = column 69
# pH_T4 = column 72
# TMP_T6 = column 75
# pH_T6 = column 78
# TMP_T5 = column 81
# pH_T5 = column 84
# TMP_T1 = column 87
# pH_T1 = column 90
# TMP_T7 = column 93
# pH_T7 = column 96
# TMP_T3 = column 99
# pH_T3 = column 102
# TMP_T2 = column 105
# pH_T2 = column 108 pH_T2
# NOTE: 18 in total above
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,69,72,75,78,81,84,87,90,93,96,99,102,105,108)] #select columns
colnames(Probe.Data) <- c("Date.Time", "TMP_T0", "pH_T0", "TMP_T4", "pH_T4", "TMP_T6","pH_T6",
"TMP_T5", "pH_T5", "TMP_T1", "pH_T1", "TMP_T7", "pH_T7", "TMP_T3",
"pH_T3", "TMP_T2", "pH_T2")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
# tail(Probe.Data) # to view the newest data and compare to APEX fusion for assigning column names
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Output/20190815_Apex_Data_Output.data.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Graphs/20190815_Apex_Data_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(15, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(6, 8.5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.2.1:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.1:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.200:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.2.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=20030
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=190303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=20200303&days=8") #read in the date plus x days of Apex data
#Title: Respiration Analysis
#Author: Sam Gurr
#Edited by: Sam Gurr
#Date Last Modified: 20190822
#See Readme file for details
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
library(devtools)
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
if ("lmtest" %in% rownames(installed.packages()) == 'FALSE') install.packages('lmtest')
if ("car" %in% rownames(installed.packages()) == 'FALSE') install.packages('car')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
library('car')
library('lmtest')
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
library('car')
library('lmtest')
library(ggplot2)        # Version 2.2.1, Packaged: 2016-12-30, Depends: R (>= 3.1)Imports: digest, grid, gtable (>= 0.1.1), MASS, plyr (>= 1.7.1),reshape2, scales (>= 0.4.1), stats, tibble, lazyeval
library(ggpubr)         # Version: 0.1.8 Date: 2018-08-30, Depends: R (>= 3.1.0), ggplot2, magrittrImports: ggrepel, grid, ggsci, stats, utils, tidyr, purrr, dplyr(>=0.7.1), cowplot, ggsignif, scales, gridExtra, glue, polynom
library(Rmisc)          # Version: 1.5 Packaged: 2013-10-21, Depends: lattice, plyr
library(plotrix)        # Version: 3.7-4, Date/Publication: 2018-10-03
library(lsmeans)        # Version: 2.27-62, Date/Publication: 2018-05-11, Depends: methods, R (>= 3.2)
# Set Working Directory:
setwd("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/")
############################################################################################# #
############################################################################################# #
#########################  RESP RATE DATA ################################################### #
############################################################################################# #
############################################################################################# #
# upload relative SMR data (calculation for this table in "Resp.Tables.R")
DATA <- read.csv(file="Data/SDR_data/Final_table_for_resp_analysis.csv", header=T) #read Size.info data
DATA.pre <- DATA %>%
dplyr::filter(Date %in% 20190723) # 21-day experiment began on 20190723
DATA.experiment <- DATA %>%
dplyr::filter(Date > 20190723) # 21-day experiment began on 20190725
DATA_Days.1.14 <- DATA.experiment %>%  # divide dataset into first 14 days (same treatment)
dplyr::filter(Date < 20190808)
DATA_Days.15.21 <- DATA.experiment %>%  # and last 7 days (same treatment)
dplyr::filter(Date > 20190807)
###############################################################################  #
###############################################################################  #
################### T-test for resp rate prior to secondary exoposure       ###  #
################# after 3 months of pCO2 conditioning #########################  #
###############################################################################  #
# t.test of "pre" data prior to the experiment
ttest_summ <-t.test(resp.COUNT.µg.L.hr.indiv~Treatment.history, data=DATA.pre) # p-value = 0.5516; no difference between pCO2 treatment
ttest_summ # view tet results
#Title: Shell.size.Analysis
#Author: Sam Gurr
#Edited by: Sam Gurr
#Date Last Modified: 20190628
#See Readme file for details
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
# Load packages and pacage version/date/import/depends info
library(dplyr)          # Version 0.7.6, Packaged: 2018-06-27, Depends: R (>= 3.1.2)Imports: assertthat (>= 0.2.0), bindrcpp (>= 0.2.0.9000), glue (>=1.1.1), magrittr (>= 1.5), methods, pkgconfig (>= 2.0.1), R6(>= 2.2.2), Rcpp (>= 0.12.15), rlang (>= 0.2.0), tibble (>=1.3.1), tidyselect (>= 0.2.3), utils
library(ggplot2)        # Version 2.2.1, Packaged: 2016-12-30, Depends: R (>= 3.1)Imports: digest, grid, gtable (>= 0.1.1), MASS, plyr (>= 1.7.1),reshape2, scales (>= 0.4.1), stats, tibble, lazyeval
library(ggpubr)         # Version: 0.1.8 Date: 2018-08-30, Depends: R (>= 3.1.0), ggplot2, magrittrImports: ggrepel, grid, ggsci, stats, utils, tidyr, purrr, dplyr(>=0.7.1), cowplot, ggsignif, scales, gridExtra, glue, polynom
library(Rmisc)          # Version: 1.5 Packaged: 2013-10-21, Depends: lattice, plyr
library(plotrix)        # Version: 3.7-4, Date/Publication: 2018-10-03
library(lsmeans)        # Version: 2.27-62, Date/Publication: 2018-05-11, Depends: methods, R (>= 3.2)
library(gridExtra)      # Version: 2.3, Date/Publication: 2017-09-09, Imports: gtable, grid, grDevices, graphics, utils
library(reshape)        # Version: 0.8.7, Date/Publication: 2017-08-06, Depends: R (>= 2.6.1) Imports: plyr
library(multcompView)   # Version: 0.1-7, Date/Publication: 2015-07-31, Imports: grid
library(Rmisc)
library(lmtest)
library(car)
library(ggpubr)
#Required Data files
# Set Working Directory:
# setwd("~/MyProjects/Geoduck_Conditioning/RAnalysis/") #set working
setwd("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/")
#Load Sample Info
Size.data <- read.csv(file="Data/Shell_length/20190628_shell_size.csv", header=T) #read sample.info data
Size.data.ALL <- read.csv(file="Data/Shell_length/Shell_length_data.csv", header=T) #read sample.info data
ID.reference.all <- read.csv(file="Data/Tank.ID.reference.subsequent.csv", header=T) #read sample.info data
################################################################################################################### #
# DATA CARPENTRY FOR FIGURES AND STATISTICAL ANALYSIS   ########################################################### #
################################################################################################################### #
# Merge ID.ref with shell size; select desired columns; divide into treatment periods; rbind to one table
# ID ref modifications - filter tank IDs for treatment periods
# ID.reference.D.1.14 <- ID.reference.all %>%  dplyr::filter(Tank.ID == 1:36) %>%  dplyr::select(Tank.ID, INITIAL.TREATMENT.ID)
# ID.reference.D.15.21 <- ID.reference.all  %>%  dplyr::select(Tank.ID, TREATMENT.ID.TOTAL)
# filter and select dates of experiment and ommit NAs
Size.data.EXPERIMENT <- Size.data.ALL %>% dplyr::filter(Date > 20190722) %>%  dplyr::select(Date, Tank.ID, Sw.Condition, Length, Notes, Tank.ID.SPLIT) # select data since 20190723
Size.data.EXPERIMENT <- Size.data.EXPERIMENT %>% filter_at(vars(Tank.ID), any_vars(!is.na(.))) # only ommit NA of Tank.ID
Size.data.EXPERIMENT # view table
# modify ID ref columns and merge with shell size table = shell_size_data
ID.reference.short <- ID.reference.all %>% dplyr::select(Tank.ID,TREATMENT.ID.TOTAL, Tank.ID.SPLIT) # select columns desired from ID.references to merge with shell size below
shell_size_data <- merge(Size.data.EXPERIMENT,ID.reference.short,by="Tank.ID") # merge shell size data and ID reference
shell_size_data <- shell_size_data %>%  dplyr::select(-Tank.ID.SPLIT.x)
colnames(shell_size_data)[7] <- "Tank.ID.SPLIT"
# modify shell_size_data for targetted columns and create new columns for different treatments
shell_size_data <- shell_size_data %>% dplyr::select(Date, Length, TREATMENT.ID.TOTAL,Tank.ID, Tank.ID.SPLIT)
shell_size_data$Treatment_history <- substr(shell_size_data$TREATMENT.ID.TOTAL, 1,1) # new column for treatment history
shell_size_data$Treatment.EXP_1 <- substr(shell_size_data$TREATMENT.ID.TOTAL, 3,3) # new column for d1-7 exposure
shell_size_data$Treatment.EXP_2 <- substr(shell_size_data$TREATMENT.ID.TOTAL, 4,4) # new column for d 15-21 exposure
# divide shell_size_data into the 4 different periods (pre, first 7 days, second 7 days, third 7 days of 21-day experiment)
# (1) Pre-experiment data
#Size.pre <- shell_size_data %>% dplyr::filter(Date %in% c(20190723,20190724))
Size.pre <- shell_size_data %>% dplyr::filter(Date %in% c(20190724))
Size.pre$Treatment.EXP_1 <- "NA" # first exposure NA - not needed in figure or analysis
Size.pre$Treatment.EXP_2 <- "NA" # second exposure NA - not needed in figure or analysis # IMPORTANT! PRE-EXPERIMENT DATA
# (2 and 3) First 14 days of the expeiment - Same treatments for figure and analsis (hisotyr and Exp_1 NOT Exp_2 during last 7-day period)
Size.D.1.14 <- shell_size_data %>% dplyr::filter(Date %in% 20190725:20190807)  # filter data with six treatments
Size.D.1.14$Treatment.EXP_2 <- "NA" # second exposure NA - not needed in figure or analysis
Size.D.1.7 <- Size.D.1.14 %>% dplyr::filter(Date < 20190801 ) # IMPORTANT! DAYS 1 - 7 DATA
Size.D.8.14 <- Size.D.1.14 %>% dplyr::filter(Date > 20190731) # IMPORTANT! DAYS 8 - 14 DATA
# (4) Last 7 days of the experiment
Size.D.15.21 <- shell_size_data %>% dplyr::filter(Date > 20190807)  # IMPORTANT! DAYS 15 - 21 DATA
# bind all data to one table
SizeTableFINAL <- rbind(Size.pre, Size.D.1.14, Size.D.15.21)
################################################################################################################### #
# DATA CARPENTRY FOR AVERAGE SHELL LENTH TO INITIAL VALUES BY BIOLOGICAL REPLICATE (CUP)        ################### #
################################################################################################################### #
# make a table of the mean and standard deviation of the pre experiment sizes by Tank.ID
pre_experiment <- SizeTableFINAL %>% filter(Date %in% 20190724)
tapply(pre_experiment$Length, pre_experiment$Treatment_history, mean) # mean value of Ambient and Elevated animals
PRE.Table <- as.table(tapply(pre_experiment$Length, (paste(pre_experiment$Treatment_history, pre_experiment$Tank.ID.SPLIT, sep ="_")), mean)) # mean value of treatment and tray
PRE.Table.melt <- melt(PRE.Table, id.vars=c("Tank.ID.SPLIT"))
PRE.Table.melt$Tank.ID.SPLIT <- substr(PRE.Table.melt$indices, 3,7)
MERGE_averages <- merge(SizeTableFINAL, PRE.Table.melt, by = "Tank.ID.SPLIT")
MERGE_averages$length.DIFF <- MERGE_averages$Length - MERGE_averages$value  # calculate the length difference
# PLAY OF THE DATA A BIT AND PLOT
#x_after <- MERGE_averages %>%  filter(Date > 20190724)
#x_20190731$Treatment_hist_EXP1 <- paste(a=x_20190731$Treatment_history, x_20190731$Treatment.EXP_1, sep = "")
#ggboxplot(x_after, x = "Date", y = "length.DIFF",  ylab = "length.difference (mm)",  fill = "Treatment.EXP_1",
#          palette = c( "rickandmorty"),add = "jitter", title = "Length_difference", xlab = "Shell length")
Size.DIFF.D.1.14 <- MERGE_averages %>% dplyr::filter(Date %in% 20190725:20190807)  # filter data with six treatments
Size.DIFF.D.1.7 <- Size.DIFF.D.1.14 %>% dplyr::filter(Date < 20190801 ) # IMPORTANT! DAYS 1 - 7 DATA
Size.DIFF.D.8.14 <- Size.DIFF.D.1.14 %>% dplyr::filter(Date > 20190731) # IMPORTANT! DAYS 8 - 14 DATA
Size.DIFF.D.15.21 <- MERGE_averages %>% dplyr::filter(Date > 20190807)  # IMPORTANT! DAYS 15 - 21 DATA
################################################################################################################### #
# STATISTICAL ANALYSIS  ########################################################################################### #
################################################################################################################### #
# PRE-EXPERIMENT T-TEST ------------------------------------------------------------------------------------------- #
library(ggpubr)
# t.test of "pre" data prior to the experiment
t.test(Length~Treatment_history, data=Size.pre) # p-value = 4.491e-05; di
