library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=190722&days=14") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
head(Apex.Data) # check the first few lines to see the first few hrs of the extracted data
tail(Apex.Data) # check to end to dertmine if the xmlParse extracted up to present day
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=190722&days=14") #read in the date plus x days of Apex data
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=190722&days=14") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
head(Apex.Data) # check the first few lines to see the first few hrs of the extracted data
tail(Apex.Data) # check to end to dertmine if the xmlParse extracted up to present day
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
tail(Apex.Data2) # check most recent data
names(Apex.Data2)
# Column names modified as of 20190220 - new apex (from broodstock set-up) moved to conicals due to a malfunction
# Date.Time = column 3
# TMP_T0 = column 6
# pH_T0= column 9
# TMP_T4 = column 69
# pH_T4 = column 72
# TMP_T6 = column 75
# pH_T6 = column 78
# TMP_T5 = column 81
# pH_T5 = column 84
# TMP_T1 = column 87
# pH_T1 = column 90
# TMP_T7 = column 93
# pH_T7 = column 96
# TMP_T3 = column 99
# pH_T3 = column 102
# TMP_T2 = column 105
# pH_T2 = column 108 pH_T2
# NOTE: 18 in total above
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,69,72,75,78,81,84,87,90,93,96,99,102,105,108)] #select columns
colnames(Probe.Data) <- c("Date.Time", "TMP_T0", "pH_T0", "TMP_T4", "pH_T4", "TMP_T6","pH_T6",
"TMP_T5", "pH_T5", "TMP_T1", "pH_T1", "TMP_T7", "pH_T7", "TMP_T3",
"pH_T3", "TMP_T2", "pH_T2")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
# tail(Probe.Data) # to view the newest data and compare to APEX fusion for assigning column names
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Output/20190805_Apex_Data_Output.data.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Graphs/20190805_Apex_Data_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(10, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(3.5, 8.5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Graphs/20190805_Apex_Data_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(15, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(6, 8.5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
ed reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=190809&days=7") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
head(Apex.Data) # check the first few lines to see the first few hrs of the extracted data
tail(Apex.Data) # check to end to dertmine if the xmlParse extracted up to present day
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
tail(Apex.Data2) # check most recent data
names(Apex.Data2)
tail(Apex.Data2) # check most recent data
# Column names modified as of 20190220 - new apex (from broodstock set-up) moved to conicals due to a malfunction
# Date.Time = column 3
# TMP_T0 = column 6
# pH_T0= column 9
# TMP_T4 = column 69
# pH_T4 = column 72
# TMP_T6 = column 75
# pH_T6 = column 78
# TMP_T5 = column 81
# pH_T5 = column 84
# TMP_T1 = column 87
# pH_T1 = column 90
# TMP_T7 = column 93
# pH_T7 = column 96
# TMP_T3 = column 99
# pH_T3 = column 102
# TMP_T2 = column 105
# pH_T2 = column 108 pH_T2
# NOTE: 18 in total above
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,69,72,75,78,81,84,87,90,93,96,99,102,105,108)] #select columns
colnames(Probe.Data) <- c("Date.Time", "TMP_T0", "pH_T0", "TMP_T4", "pH_T4", "TMP_T6","pH_T6",
"TMP_T5", "pH_T5", "TMP_T1", "pH_T1", "TMP_T7", "pH_T7", "TMP_T3",
"pH_T3", "TMP_T2", "pH_T2")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
# tail(Probe.Data) # to view the newest data and compare to APEX fusion for assigning column names
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Output/20190815_Apex_Data_Output.data.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/Data/Apex_data/Graphs/20190815_Apex_Data_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(15, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(6, 8.5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.2.1:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.1:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.200:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.2.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in the date plus x days of Apex data
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=20030
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
# T7 = ambient conditions (second heath tray in stack)
#added reminders on lines 39 and 43 to prevent overwritting files ->  SJG
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=200303&days=8") #read in t
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=190303&days=8") #read in the date plus x days of Apex data
xmlfile <- xmlParse("http://192.168.1.100:80/cgi-bin/datalog.xml?sdate=20200303&days=8") #read in the date plus x days of Apex data
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
library("segmented")
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
# Load packages and pacage version/date/import/depends info
library(dplyr)          # Version 0.7.6, Packaged: 2018-06-27, Depends: R (>= 3.1.2)Imports: assertthat (>= 0.2.0), bindrcpp (>= 0.2.0.9000), glue (>=1.1.1), magrittr (>= 1.5), methods, pkgconfig (>= 2.0.1), R6(>= 2.2.2), Rcpp (>= 0.12.15), rlang (>= 0.2.0), tibble (>=1.3.1), tidyselect (>= 0.2.3), utils
library(ggplot2)        # Version 2.2.1, Packaged: 2016-12-30, Depends: R (>= 3.1)Imports: digest, grid, gtable (>= 0.1.1), MASS, plyr (>= 1.7.1),reshape2, scales (>= 0.4.1), stats, tibble, lazyeval
library(ggpubr)         # Version: 0.1.8 Date: 2018-08-30, Depends: R (>= 3.1.0), ggplot2, magrittrImports: ggrepel, grid, ggsci, stats, utils, tidyr, purrr, dplyr(>=0.7.1), cowplot, ggsignif, scales, gridExtra, glue, polynom
library(Rmisc)          # Version: 1.5 Packaged: 2013-10-21, Depends: lattice, plyr
library(plotrix)        # Version: 3.7-4, Date/Publication: 2018-10-03
library(lsmeans)        # Version: 2.27-62, Date/Publication: 2018-05-11, Depends: methods, R (>= 3.2)
library(gridExtra)      # Version: 2.3, Date/Publication: 2017-09-09, Imports: gtable, grid, grDevices, graphics, utils
library(reshape)        # Version: 0.8.7, Date/Publication: 2017-08-06, Depends: R (>= 2.6.1) Imports: plyr
library(multcompView)   # Version: 0.1-7, Date/Publication: 2015-07-31, Imports: grid
library(Rmisc)
library(lmtest)
library(car)
library(ggpubr)
# Set Working Directory:
# setwd("~/MyProjects/Geoduck_Conditioning/RAnalysis/") #set working
setwd("C:/Users/samjg/Documents/My_Projects/Inragenerational_thresholds_OA/RAnalysis/")
#Load Sample Info
Size.data <- read.csv(file="Data/Shell_length/20190628_shell_size.csv", header=T) #read sample.info data
Size.data.ALL <- read.csv(file="Data/Shell_length/Shell_length_data.csv", header=T) #read sample.info data
ID.reference.all <- read.csv(file="Data/Tank.ID.reference.subsequent.csv", header=T) #read sample.info data
D.reference.D.1.14 <- ID.reference.all %>%  dplyr::filter(Tank.ID == 1:36) %>%  dplyr::select(Tank.ID, INITIAL.TREATMENT.ID)
# ID.reference.D.15.21 <- ID.reference.all  %>%  dplyr::select(Tank.ID, TREATMENT.ID.TOTAL)
# filter and select dates of experiment and ommit NAs
Size.data.EXPERIMENT <- Size.data.ALL %>% dplyr::filter(Date > 20190722) %>%  dplyr::select(Date, Tank.ID, Sw.Condition, Length, Notes, Tank.ID.SPLIT) # select data since 20190723
Size.data.EXPERIMENT <- Size.data.EXPERIMENT %>% filter_at(vars(Tank.ID), any_vars(!is.na(.))) # only ommit NA of Tank.ID
Size.data.EXPERIMENT # view table
# modify ID ref columns and merge with shell size table = shell_size_data
ID.reference.short <- ID.reference.all %>% dplyr::select(Tank.ID,TREATMENT.ID.TOTAL, Tank.ID.SPLIT) # select columns desired from ID.references to merge with shell size below
shell_size_data <- merge(Size.data.EXPERIMENT,ID.reference.short,by="Tank.ID") # merge shell size data and ID reference
shell_size_data <- shell_size_data %>%  dplyr::select(-Tank.ID.SPLIT.x)
colnames(shell_size_data)[7] <- "Tank.ID.SPLIT"
# modify shell_size_data for targetted columns and create new columns for different treatments
shell_size_data <- shell_size_data %>% dplyr::select(Date, Length, TREATMENT.ID.TOTAL,Tank.ID, Tank.ID.SPLIT)
shell_size_data$Treatment_history <- substr(shell_size_data$TREATMENT.ID.TOTAL, 1,1) # new column for treatment history
shell_size_data$Treatment.EXP_1 <- substr(shell_size_data$TREATMENT.ID.TOTAL, 3,3) # new column for d1-7 exposure
shell_size_data$Treatment.EXP_2 <- substr(shell_size_data$TREATMENT.ID.TOTAL, 4,4) # new column for d 15-21 exposure
# divide shell_size_data into the 4 different periods (pre, first 7 days, second 7 days, third 7 days of 21-day experiment)
# (1) Pre-experiment data
#Size.pre <- shell_size_data %>% dplyr::filter(Date %in% c(20190723,20190724))
Size.pre <- shell_size_data %>% dplyr::filter(Date %in% c(20190724))
Size.pre$Treatment.EXP_1 <- "NA" # first exposure NA - not needed in figure or analysis
Size.pre$Treatment.EXP_2 <- "NA" # second exposure NA - not needed in figure or analysis # IMPORTANT! PRE-EXPERIMENT DATA
# (2 and 3) First 14 days of the expeiment - Same treatments for figure and analsis (hisotyr and Exp_1 NOT Exp_2 during last 7-day period)
Size.D.1.14 <- shell_size_data %>% dplyr::filter(Date %in% 20190725:20190807)  # filter data with six treatments
Size.D.1.14$Treatment.EXP_2 <- "NA" # second exposure NA - not needed in figure or analysis
Size.D.1.7 <- Size.D.1.14 %>% dplyr::filter(Date < 20190801 ) # IMPORTANT! DAYS 1 - 7 DATA
Size.D.8.14 <- Size.D.1.14 %>% dplyr::filter(Date > 20190731) # IMPORTANT! DAYS 8 - 14 DATA
# (4) Last 7 days of the experiment
Size.D.15.21 <- shell_size_data %>% dplyr::filter(Date > 20190807)  # IMPORTANT! DAYS 15 - 21 DATA
# bind all data to one table
SizeTableFINAL <- rbind(Size.pre, Size.D.1.14, Size.D.15.21)
################################################################################################################### #
# DATA CARPENTRY FOR AVERAGE SHELL LENTH TO INITIAL VALUES BY BIOLOGICAL REPLICATE (CUP)        ################### #
###################################
# make date a character to address as a factor in the model
Size.D.15.21$Date <- as.character(Size.D.15.21$Date)
#interaction plots
interaction.plot(Size.D.15.21$Treatment_history, Size.D.15.21$Date, Size.D.15.21$Length)
interaction.plot(Size.D.15.21$Treatment_history, Size.D.15.21$Treatment.EXP_1, Size.D.15.21$Length)
interaction.plot(Size.D.15.21$Date, Size.D.15.21$Treatment.EXP_1, Size.D.15.21$Length)
# four way ANOVA treatment and date
fourwayanova_D15.21 <-aov(Length ~ Treatment_history*Treatment.EXP_1*Treatment.EXP_2*Date, data=Size.D.15.21)
shapiro.test(residuals(fourwayanova_D15.21)) # shaprio wilk test of model residuals p = 0.0005398;  non-normal distribution
hist((residuals(fourwayanova_D15.21)))# histogram of model - looks normal
boxplot(residuals(fourwayanova_D15.21)) #plot boxplot of residuals - some outliers present
plot(fitted(fourwayanova_D15.21),residuals(fourwayanova_D15.21)) # plot residuals
qqnorm(residuals(fourwayanova_D15.21)) # qqplot - looks normal
# summary of transformed data
summary(fourwayanova_D15.21) # significant effect of time and treatment history
TukeyHSD(fourwayanova_D15.21, conf.level=0.95) # tukey test on the effect of treatment with 95% confidence
# model on transformed data
Size.D.15.21$Length.log <- log(Size.D.15.21$Length)
fourwayanova_D15.21.LOG <- aov(Length.log ~ Treatment_history*Treatment.EXP_1*Treatment.EXP_2*Date, data=Size.D.15.21) # run the model
shapiro.test(residuals(fourwayanova_D15.21.LOG)) # shaprio wilk test of model residuals p = 0.377; normal distribution (log worked)
boxplot(residuals(fourwayanova_D15.21.LOG)) #plot boxplot of residuals - some outliers present
hist((residuals(fourwayanova_D15.21.LOG))) # histogram of model - looks normal
plot(fitted(fourwayanova_D15.21.LOG),residuals(fourwayanova_D15.21.LOG)) # plot residuals
qqnorm(residuals(fourwayanova_D15.21.LOG)) # qqplot - looks normal
# summary of transformed data
summary(fourwayanova_D15.21.LOG) # significant effect of time and treatment history
TukeyHSD(fourwayanova_D15.21.LOG, conf.level=0.95) # tukey test on the effect of treatment with 95% confidence
# four way ANOVA treatment and date
fourwayanova_D15.21 <-aov(Length ~ Treatment_history*Treatment.EXP_1*Treatment.EXP_2*Date, data=Size.D.15.21)
shapiro.test(residuals(fourwayanova_D15.21)) # shaprio wilk test of model residuals p = 0.0005398;  non-normal distribution
hist((residuals(fourwayanova_D15.21)))# histogram of model - looks normal
boxplot(residuals(fourwayanova_D15.21)) #plot boxplot of residuals - some outliers present
plot(fitted(fourwayanova_D15.21),residuals(fourwayanova_D15.21)) # plot residuals
qqnorm(residuals(fourwayanova_D15.21)) # qqplot - looks normal
# summary of transformed data
summary(fourwayanova_D15.21) # significant effect of time and treatment history
TukeyHSD(fourwayanova_D15.21, conf.level=0.95) # tukey test on the effect of treatment with 95% confidence
# summary of transformed data
summary(fourwayanova_D15.21) # significant effect of time and treatment history
TukeyHSD(fourwayanova_D15.21, conf.level=0.95) # tukey test on the effect of treatment with 95% confidence
# summary of transformed data
summary(fourwayanova_D15.21) # significant effect of time and treatment history
TukeyHSD(fourwayanova_D15.21, Treatment_history:Treatment.EXP_1:Treatment.EXP_2, conf.level=0.95) # tukey test on the effect of treatment with 95% confidence
TukeyHSD(fourwayanova_D15.21, Treatment_history*Treatment.EXP_1*Treatment.EXP_2, conf.level=0.95) # tukey test on the effect of treatment with 95% confidence
# summary of transformed data
summary(fourwayanova_D15.21) # significant effect of time and treatment history
TukeyHSD(fourwayanova_D15.21, Treatment.EXP_1*Treatment.EXP_2, conf.level=0.95) # tukey test on the effect of treatment with 95% confidence
TukeyHSD(fourwayanova_D15.21, Treatment.EXP_1:Treatment.EXP_2, conf.level=0.95) # tukey test on the effect of treatment with 95% confidence
TukeyHSD?
A:M:M:20190814-E:A:A:20190808 -1.1557222222 -2.139535460 -0.17190898 0.0036865
?TukeyHSD
TukeyHSD(fourwayanova_D15.21, "Treatment_history*Treatment.EXP_1*Treatment.EXP_2", conf.level=0.95) # tukey test on the effect of treatment with 95% confidence
TukeyHSD(fourwayanova_D15.21, "Treatment_history, Treatment.EXP_1, Treatment.EXP_2", conf.level=0.95) # tukey test on the effect of treatment with 95% confidence
TukeyHSD(fourwayanova_D15.21, which ="Treatment_history:Treatment.EXP_1:Treatment.EXP_2", conf.level=0.95) # tukey test on the effect of treatment with 95% confidence
#interaction plots
interaction.plot(Size.D.15.21$Treatment_history, Size.D.15.21$Date, Size.D.15.21$Length)
interaction.plot(Size.D.15.21$Treatment_history, Size.D.15.21$Treatment.EXP_1, Size.D.15.21$Length)
interaction.plot(Size.D.15.21$Date, Size.D.15.21$Treatment.EXP_1, Size.D.15.21$Length)
Size.D.15.21
Size.D.15.21 %>% dplyr::group_by(TREATMENT.ID.TOTAL) %>% mean()
Size.D.15.21 %>% dplyr::group_by(Size.D.15.21$TREATMENT.ID.TOTAL) %>% mean(Size.D.15.21$Length)
Size.D.15.21$TREATMENT.ID.TOTAL
Size.D.15.21$Length
MEANS.D12.21 <- Size.D.15.21 %>% dplyr::group_by(Size.D.15.21$TREATMENT.ID.TOTAL) %>% mean(Size.D.15.21$Length)
MEANS.D12.21 <- Size.D.15.21 %>% dplyr::group_by(Size.D.15.21$TREATMENT.ID.TOTAL) %>% mean(as.numeric(Size.D.15.21$Length))
MEANS.D12.21 <- Size.D.15.21 %>% group_by(Size.D.15.21$TREATMENT.ID.TOTAL) %>% mean(as.numeric(Size.D.15.21$Length))
MEANS.D12.21 <- Size.D.15.21 %>% group_by(Size.D.15.21$TREATMENT.ID.TOTAL) %>% pull(Length) %>%  mean
MEANS.D12.21
MEANS.D12.21 <- Size.D.15.21 %>% group_by(Size.D.15.21$TREATMENT.ID.TOTAL) %>% mean(Length)
MEANS.D12.21 <- Size.D.15.21 %>% group_by(TREATMENT.ID.TOTAL) %>% mean(Length)
MEAN.EHSM <- Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean
MEAN.EHSM
{((Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean) -
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "AHSM") %>% pull(Length) %>% mean))/
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean)}*100
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "AHSM") %>% pull(Length) %>% mean)
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean)
((Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean) -
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "AHSM") %>% pull(Length) %>% mean))
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean)
x <- 100/8.65
x*0.64
x*0.65
# E:S:M Vs. A:M:M == EHSM is % larger
{((Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean) -
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "AHMM") %>% pull(Length) %>% mean))/
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean)}*100
# E:S:M Vs. A:M:M == EHSM is 9.70% larger
{((Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean) -
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSA") %>% pull(Length) %>% mean))/
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean)}*100
# E:S:M Vs. A:M:A  == EHSM is 9.436% larger
{((Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean) -
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "AHMA") %>% pull(Length) %>% mean))/
(Size.D.15.21 %>% filter(TREATMENT.ID.TOTAL == "EHSM") %>% pull(Length) %>% mean)}*100
average_percent_shell_D15.21 <- (9.70+9.436+8.65)/3
average_percent_shell_D15.21
(9.70+9.436+8.65)/3 # 9.262% greater shell size by mod conditioned animals exposure to secondary severe and tertiary moderate pCO2
